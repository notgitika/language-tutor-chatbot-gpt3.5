{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcgNFvCDr6RZ"
      },
      "source": [
        "# Structure of the project (Instructors only!)\n",
        "\n",
        "1. Go module by module -- first translate, then explain (and summarize) and then practice convo\n",
        "2. Have a few small tasks for students. For instance, in the translate function, have them discover a way to use the GPT-3 model API calls to automatically guess the language the user is typing in instead of them explicitly entering a source langugage. Will mostly have them do the entire 'expxlanation' task on their own as it is very similar.\n",
        "3. We will be using few-shot learning on the 'practice' module with a 'before' and 'after' so that they learn that few-shot learning gives them better results.\n",
        "4. \n",
        "\n",
        "The end :))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMZrDP_TrhsI"
      },
      "source": [
        "# GPT-3 Powered Language Tutor\n",
        "\n",
        "Welcome to the GPT-3 Language Tutor! This interactive Jupyter Notebook is designed to help you build an interactive language tutor using OpenAI's GPT-3 model. In this project, you can translate sentences from one language to another, provide detailed explanations for sentences, and even practice conversations with you :)\n",
        "\n",
        "![](https://media2.giphy.com/media/mNfvtK90scVTF20Jye/giphy.gif?cid=ecf05e47nabgmejh8i8p27zix9xci6ndhjuwjwgfy3ko9wnv&ep=v1_gifs_search&rid=giphy.gif&ct=g)\n",
        "\n",
        "### Let's explore each functionality in detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBi-Ojrb6eca",
        "outputId": "cc3ab073-e1d6-4e54-dfe9-ee8c8301e309"
      },
      "outputs": [],
      "source": [
        "# download all libraries required\n",
        "\n",
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnzisAcU5eqw"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "\n",
        "import openai\n",
        "import logging as logger # this is useful for debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXim09296LNM"
      },
      "outputs": [],
      "source": [
        "# This secret openAI key should not be shared\n",
        "\n",
        "openai.api_key = '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'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsrjOknOl0GS"
      },
      "source": [
        "## This is where we start our code.\n",
        "\n",
        "We will be developing each function one-by-one first and then integrate them into one chatbot\n",
        "\n",
        "---\n",
        "\n",
        "According to the scope of this project, we want to have our chatbot do the following things:\n",
        "1. Translate a sentence from one language to another.\n",
        "2. Practice with the user through a conversation.\n",
        "3. Provide explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcmcxxP3mDd1"
      },
      "source": [
        "## 1: Translate a sentence from one language to another\n",
        "\n",
        "\n",
        "![](https://media3.giphy.com/media/vrcxO2t1CLV0k/giphy.gif?cid=ecf05e47hhlnmu8q87vycl0zkx4vzd6mpwerk3y6whhau7eu&ep=v1_gifs_search&rid=giphy.gif&ct=g)\n",
        "\n",
        "We start off with simple translation from one language to another"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLLdQnjymJce"
      },
      "outputs": [],
      "source": [
        "chat_history = []\n",
        "# We want to track chat history to preserve the context the user is talking in\n",
        "\n",
        "'''This is a Function to generate a response using GPT-3\n",
        "You can learn more about the API at this link: https://platform.openai.com/docs/introduction.\n",
        "I highly suggest you spend a good time initially just understanding what this transformer is based on and interacting with the API'''\n",
        "\n",
        "def generate_response(input_text):\n",
        "    api_call = openai.ChatCompletion.create(\n",
        "        model='gpt-3.5-turbo',  # you can experiment with different engines here to compare the results\n",
        "        messages=chat_history + [{'role': 'user', 'content': input_text}],\n",
        "        max_tokens=200,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "\n",
        "    # Debugging -- print this to actually see how the response by the api is structured\n",
        "\n",
        "    # print(f'choices {response[\"choices\"]}')\n",
        "    # print(f'messages {response[\"choices\"][0][\"message\"]}')\n",
        "    # print(f'content {response[\"choices\"][0][\"message\"][\"content\"]}')\n",
        "\n",
        "    response = api_call[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIYOWHt7mYg6"
      },
      "outputs": [],
      "source": [
        "def perform_translation(user_input):\n",
        "    sentence = user_input.replace('translate', '').strip()\n",
        "    source_lang = input(\"Enter the source language: \")\n",
        "    target_lang = input(\"Enter the target language: \")\n",
        "\n",
        "    translation_prompt = f\"Translate: {sentence} from {source_lang} to {target_lang}\\n\"\n",
        "    response = generate_response(translation_prompt)\n",
        "\n",
        "    logger.info(f'response {response}')\n",
        "\n",
        "    chat_history.append({'role': 'user', 'content': translation_prompt})\n",
        "    chat_history.append({'role': 'assistant', 'content': response})\n",
        "\n",
        "    return f\"Translation: {response}\"\n",
        "\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGq4d4ZWniNQ"
      },
      "outputs": [],
      "source": [
        "def process_input(user_input):\n",
        "    if user_input.lower().startswith('translate'):\n",
        "        return perform_translation(user_input)\n",
        "    else:\n",
        "        return \"I'm sorry, I can only handle translation requests at the moment :(\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC7ZqpA46rM6",
        "outputId": "17270940-6670-42f0-b6b6-d178b3b2c36f"
      },
      "outputs": [],
      "source": [
        "# Main loop for the tranlation chatbot\n",
        "\n",
        "while True:\n",
        "\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "    else:\n",
        "        bot_response = process_input(user_input)\n",
        "        print(\"Bot:\", bot_response)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBYlHXajn-oK"
      },
      "source": [
        "#### Is it necessary to make the user enter the source language each time?\n",
        "#### **No!**\n",
        "#### GPT-3 is more than capable to automate this task :)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Task 1:**\n",
        "Write a function that would guess the language user has typed in and automatically use it in the translate function as 'source language'.\n",
        "\n",
        "Your edited translate function would not have the user enter the source language and would instead just have the 'target language' input from the user.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJk3eKECoOgk"
      },
      "outputs": [],
      "source": [
        "## This would be empty and would be a task to be done by the students\n",
        "\n",
        "\n",
        "## One of the answers!!\n",
        "\n",
        "def generate_language(prompt):\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=100,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.7,\n",
        "        top_p=1.0,\n",
        "        frequency_penalty=0.0,\n",
        "        presence_penalty=0.0\n",
        "    )\n",
        "\n",
        "    return response.choices[0].text.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F-BX3RSp9DL"
      },
      "source": [
        "Execute the translation function again below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lsq2nFDdySR"
      },
      "outputs": [],
      "source": [
        "# Final execution of the translate function and testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUYX0rQFcdux"
      },
      "source": [
        "---\n",
        "\n",
        "## 2: Explain a paragraph in another language\n",
        "\n",
        "![](https://media1.giphy.com/media/WhTC5v5qQP4yAUvGKz/giphy.gif?cid=ecf05e47katdeex6jw5m5dvwy8dcvmf1063ovsqlejemgid9&ep=v1_gifs_search&rid=giphy.gif&ct=g)\n",
        "\n",
        "\n",
        "You can choose how you want the chatbot to explain the text\n",
        "It can either:\n",
        "-  explain what the text means\n",
        "-  do a sentence-by-sentence explanation with the detailed explanation of the nuances\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRKeYDzWp8oJ"
      },
      "outputs": [],
      "source": [
        "chat_history = []\n",
        "\n",
        "# do not have to rewrite the 'generate_response()' method :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnYp0m2tee9z"
      },
      "outputs": [],
      "source": [
        "def summarize_text(user_input):\n",
        "    text = user_input.replace('summarize', '').strip()\n",
        "\n",
        "    source_language = generate_language(text)\n",
        "    target_language = input(\"Enter the language you want the summarizationS in: \")\n",
        "\n",
        "    summary_prompt = f\"Summarize the following text {text} in {target_language}\\n\"\n",
        "    response = generate_response(summary_prompt)\n",
        "\n",
        "    chat_history.append({'role': 'user', 'content': summary_prompt})\n",
        "    chat_history.append({'role': 'assistant', 'content': response})\n",
        "\n",
        "    return f\"Summary: {response}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFdUi_6qekZC"
      },
      "outputs": [],
      "source": [
        "def explain_text_sentence_by_sentence(user_input):\n",
        "    text = user_input.replace('explain', '').strip()\n",
        "\n",
        "    sentences = text.split('. ')\n",
        "    explanation_prompt = \"Explain the following sentences:\\n\"\n",
        "\n",
        "    source_language = generate_language(text)\n",
        "    target_language = input(\"Enter the language you want the explanation in: \")\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # translated_sentence = translate_text(sentence, source_lang, target_lang)\n",
        "        explanation_prompt += f\"Sentence: {sentence}\\n\"\n",
        "\n",
        "\n",
        "    response = generate_response(f'Explain the following text in detail. Include important details about vocabulary and grammar: {explanation_prompt} in {target_language}')\n",
        "    # bot_reply = translate(response, target_language)\n",
        "\n",
        "    chat_history.append({'role': 'user', 'content': explanation_prompt})\n",
        "    chat_history.append({'role': 'assistant', 'content': response})\n",
        "\n",
        "    return f\"Explanation: {response}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FNnSihgek0o"
      },
      "outputs": [],
      "source": [
        "def process_input(user_input):\n",
        "    if user_input.lower().startswith('summarize'):\n",
        "        return summarize_text(user_input)\n",
        "    elif user_input.lower().startswith('explain'):\n",
        "        return explain_text_sentence_by_sentence(user_input)\n",
        "    else:\n",
        "        return \"I'm sorry, I can only handle summarization and sentence-by-sentence explanation requests at the moment.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnnWpTQ4eoXX",
        "outputId": "94c5d04a-2cb8-4444-a262-df77e468d8f6"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "    else:\n",
        "        bot_response = process_input(user_input)\n",
        "        print(\"Bot:\", bot_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBHHqdrCmEBW"
      },
      "source": [
        "## Try it yourself!\n",
        "\n",
        "Make your own little twists in this part to tweak the type of explanation you want (tip: look up one-shot or few-shot learning, which is also what we will be learning about in the next section)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5Lg66h2eSWE"
      },
      "outputs": [],
      "source": [
        "# code for one-shot learning\n",
        "# code for web-scraping for that\n",
        "\n",
        "# one shot learning examples example\n",
        "# modified explanation function\n",
        "\n",
        "def explain_text_sentence_by_sentence_one_shot(user_input):\n",
        "    text = user_input.replace('explain', '').strip()\n",
        "    source_language = generate_language(text)\n",
        "    target_language = input(\"Enter the language you want the explanation in: \")\n",
        "\n",
        "    # One-shot example in different languages\n",
        "    example = {\n",
        "    'spanish': 'Input: El gato est치 sentado en la alfombra explain in English \\n Explanation: The cat is sitting on the mat. \"El gato\":  \"Gato\" translates to \"cat,\" and it\\'s a masculine noun, so it takes the masculine article \"el\". \"est치 sentado\": \"est치\" is the third person singular form of the verb \"estar,\" which means \"to be.\" In this context, it indicates the current state of the cat, \"is.\" \"Sentado\" is the past participle of the verb \"sentar,\" which means \"to sit.\" The past participle is used in combination with the verb \"estar\" to form the present continuous tense, which conveys an ongoing action in the present. So \"est치 sentado\" translates to \"is sitting.\" \"alfombra\" can be translated as either \"mat\" or \"rug,\" depending on the context. In this sentence, it could refer to a small mat or a larger area rug. ',\n",
        "  }\n",
        "\n",
        "    sentences = text.split('. ')\n",
        "    explanation_prompt = \"Explain the following text:\\n\"\n",
        "\n",
        "    if source_language in example:\n",
        "        explanation_prompt += \"Example of the explanation:\" + example[source_language] + \"\\n\"\n",
        "\n",
        "    explanation_prompt += \"Input text: \"\n",
        "\n",
        "    for sentence in text.split('. '):\n",
        "        explanation_prompt += f\"Sentence {sentence}\\n\"\n",
        "\n",
        "\n",
        "        response = generate_response(f'Explain {explanation_prompt} in {target_language}. Go into detail explaining vocabulary and sentence structure nuanances')\n",
        "\n",
        "    chat_history.append({'role': 'user', 'content': explanation_prompt})\n",
        "    chat_history.append({'role': 'assistant', 'content': response})\n",
        "\n",
        "    return f\"Explanation: {response}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFIUWri_eSX1"
      },
      "outputs": [],
      "source": [
        "def process_input(user_input):\n",
        "    if user_input.lower().startswith('explain'):\n",
        "        return explain_text_sentence_by_sentence_one_shot(user_input)\n",
        "    else:\n",
        "        return \"I'm sorry, I can only handle sentence-by-sentence explanations at the moment.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAZLuj75eSaF",
        "outputId": "52d4bfe7-1965-483a-cf5d-0a6466547bbf"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "    else:\n",
        "        bot_response = process_input(user_input)\n",
        "        print(\"Bot:\", bot_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX7FjK6G8IRB"
      },
      "source": [
        "Task: Try few-shot learning here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bN7RhkUGE2t"
      },
      "outputs": [],
      "source": [
        "# few shot learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fZQBMQ-NO2c"
      },
      "source": [
        "---\n",
        "\n",
        "## 3: Practice with the chatbot\n",
        "\n",
        "![](https://media1.giphy.com/media/J9UXcyVW6OYN2fH0Sr/giphy.gif?cid=ecf05e47m7nchbev6576f2z71orfdbenuiakc9ku41p02ys8&ep=v1_gifs_search&rid=giphy.gif&ct=g)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtazaGHneSil"
      },
      "outputs": [],
      "source": [
        "def practice_session():\n",
        "    # target_language = input(\"Enter the language you want to practice in: \")\n",
        "\n",
        "    print(\"You are now in the practice session. Type 'exit' to end the session.\")\n",
        "    prompt = \"You will now have a conversation with the user in the language they type in. Try to correct the user if they are wrong in grammar or vocabulary.\"\n",
        "\n",
        "    # response = prompt\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        source_language = generate_language(user_input)\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        text = user_input.replace('practice', '').strip()\n",
        "\n",
        "        # For simplicity, we'll assume the chatbot always responds in the same language as the user and does not switch language in the middle\n",
        "\n",
        "        response = generate_response(f'Chat history: {chat_history}. {prompt}. Language: User: {text}')\n",
        "\n",
        "        chat_history.append({'role': 'user', 'content': user_input})\n",
        "        chat_history.append({'role': 'assistant', 'content': response})\n",
        "\n",
        "        print(\"Bot:\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dm-3x_3zPqNg"
      },
      "outputs": [],
      "source": [
        "def process_input(user_input):\n",
        "    if user_input.lower().startswith('practice'):\n",
        "        return practice_session()\n",
        "    else:\n",
        "        return \"I'm sorry, I can only handle practices at the moment.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TAJPQhsPmc2",
        "outputId": "5a25feb0-3daf-4a7e-d82a-0684a20eb46a"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "    else:\n",
        "        bot_response = process_input(user_input)\n",
        "        print(\"Bot:\", bot_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q50o80kNEE_"
      },
      "source": [
        "## Final task: Integrate it all together to have your own chatbot :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OK7gbwFx8GRk"
      },
      "outputs": [],
      "source": [
        "# Students have to do this part!\n",
        "\n",
        "'''This Function processes user input and generates a response'''\n",
        "current_mode = None\n",
        "\n",
        "def process_input(user_input):\n",
        "    global current_mode\n",
        "\n",
        "    # to limit scope, only 3 modes and the chatbot tracks chat history.\n",
        "    # if the user is in one of the modes, it stays there till the user explicitly states to go back\n",
        "\n",
        "    if current_mode is None:\n",
        "        if 'translate' in user_input.lower():\n",
        "            current_mode = 'translate'\n",
        "            return \"\"\n",
        "\n",
        "        if 'explain' in user_input.lower():\n",
        "            current_mode = 'explain'\n",
        "            return \"\"\n",
        "\n",
        "        if 'practice' in user_input.lower():\n",
        "            current_mode = 'practice'\n",
        "            return \"\"\n",
        "\n",
        "    else:\n",
        "        if current_mode == 'translate':\n",
        "            return perform_translation(user_input)\n",
        "        elif current_mode == 'summarize':\n",
        "            return summarize_text(user_input)\n",
        "        elif current_mode == 'explain':\n",
        "            return explain_text_sentence_by_sentence(user_input)\n",
        "        elif current_mode == 'practice':\n",
        "            target_lang = generate_language(user_input)\n",
        "            return practice_session(user_input, target_lang)\n",
        "\n",
        "    if 'take me back to main menu' in user_input.lower():\n",
        "        current_mode = None\n",
        "        reset_chat_history()\n",
        "        return \"Chat history has been reset. Please enter a new command.\"\n",
        "\n",
        "    return \"Invalid command. Please try again.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA902A93l-_Q"
      },
      "outputs": [],
      "source": [
        "def reset_chat_history():\n",
        "    global chat_history\n",
        "    chat_history = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgZEWvrU0X0O"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "ErUG2Ubk8QSh",
        "outputId": "01fd86f6-7989-4e9c-a2b4-d84274b665f2"
      },
      "outputs": [],
      "source": [
        "print(\"Welcome to your personalized language tutor!\")\n",
        "print()\n",
        "print(\"This tutor can do the following tasks\")\n",
        "print(\"1. Translate sentences from one language to another \\n2. Provide explanation for sentences from one language to another \\n3. Practice a conversation with you\")\n",
        "print()\n",
        "print(\"To use the translation function, use 'translate' in your input\")\n",
        "print(\"To use the summarize function, use 'summarize' in your input\")\n",
        "print(\"To use the explanation function, use 'explain' in your input\")\n",
        "print(\"To use the conversation function, use 'practice' in your input\")\n",
        "print(\"To change action, please type 'Take me back to Main Menu'\")\n",
        "\n",
        "while True:\n",
        "\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "    else:\n",
        "        bot_response = process_input(user_input)\n",
        "        print(\"Bot:\", bot_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBINKXScrgqr"
      },
      "source": [
        "### You did it!!! You built your own language tutor! Feel free to add onto this code with any other functions you might find useful <3"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
